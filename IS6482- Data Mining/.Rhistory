mydir_wd <- getwd()
setwd(mydir_wd)
# Import a csv file
VideoGameSales <- read.csv(file = "NA_sales_filtered.csv", stringsAsFactors = FALSE)
###  Set up cv parameters
df <- VideoGameSales
target <- 9
seedVal <- 500
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")
df_IBii_selected <- VideoGameSales %>% select(-Name) # VGS but without Name
VideoGameSales <- VideoGameSales %>% mutate_if(~ is.character(.) && !identical(.,VideoGameSales$Name), as.factor) # factor VGS
df_IBii_selected <- df_IBii_selected %>% mutate_if(~ is.character(.), as.factor) # factor the dataframe of VGS but without Name
set.seed(100)
index_numbers_split <- createDataPartition(df_IBii_selected$NA_Sales,p=.7,list = FALSE)
train_target <- df_IBii_selected[index_numbers_split,7]
test_target <- df_IBii_selected[-index_numbers_split,7]
train_set <- df_IBii_selected[index_numbers_split,-7] #partition the 70% to the train set
test_set <- df_IBii_selected[-index_numbers_split,-7] #simply get the rest of the set and make it test set (30% from the 100%)
# Designate a shortened name MLP for the MultilayerPercentron ANN method in RWeka
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
# MLP's default parameter values of MLP,L=0.3,M=0.2, N=500, H='a'
# L: learning rate with default=0.3
# M: momentum with default=0.2
# N: number of epochs with default=500
# H <comma separated numbers for nodes on each layer>
MLP_default_train <- MLP(train_target ~ ., data = train_set)
MLP_default_test <- MLP(test_target ~., data=test_set)
# Prediction on model
pred_MLP_train <- predict(MLP_default_train,train_set) #train set predict
pred_MLP_test <- predict(MLP_default_test,test_set) #test set predict
# evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_MLP_train,metrics_list) #train target eval
mmetric(test_target,pred_MLP_test,metrics_list) #test target eval
# MLP 2 hidden layer but learning rate is changed to L = 0.4, and hidden layer setting changed to H = x,x means 2 layers x nodes in each layer
two_hidden_layer_MLP_train <- MLP(train_target ~ .,data = train_set,control = Weka_control(L=0.4,M=0.2, N=500,H='2,2')) #train model
# Prediction on model
pred_2MLP_train <- predict(two_hidden_layer_MLP_train,train_set) #train set predict
pred_2MLP_test <- predict(two_hidden_layer_MLP_train,test_set) #test set predict
# evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_2MLP_train,metrics_list) #train target eval
mmetric(test_target,pred_2MLP_test,metrics_list) #test target eval
# ksvm on train set ( default settings)
ksvm_default_train <- ksvm(train_target ~.,data = train_set)
# prediction models
pred_ksvm_train <- predict(ksvm_default_train,train_set) #train set predict
pred_ksvm_test <- predict(ksvm_default_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_ksvm_train,metrics_list) #train target eval
mmetric(test_target,pred_ksvm_test,metrics_list) #test target eval
# New model with kernel changed to Radial Basis kernel "Gaussian" with default value C
ksvm_kernel_train <- ksvm(train_target ~.,data = train_set, kernel = "rbfdot", C = 1)
# prediction models
pred_ksvm_kernel_train <- predict(ksvm_kernel_train,train_set) #train set predict
pred_ksvm_kernel_test <- predict(ksvm_kernel_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_ksvm_kernel_train,metrics_list) #train target eval
mmetric(test_target,pred_ksvm_kernel_test,metrics_list) #test target eval
# New model value C has value higher than 1
ksvm_C_train <- ksvm(train_target ~.,data = train_set, C = 5)
# prediction models
pred_ksvm_C_train <- predict(ksvm_C_train,train_set) #train set predict
pred_ksvm_C_test <- predict(ksvm_C_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_ksvm_C_train,metrics_list) #train target eval
mmetric(test_target,pred_ksvm_C_test,metrics_list) #test target eval
# IBk on train set ( default settings)
IBk_default_train <- IBk(train_target ~.,data = train_set)
# prediction models
pred_IBk_train <- predict(IBk_default_train,train_set) #train set predict
pred_IBk_test <- predict(IBk_default_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_IBk_train,metrics_list) #train target eval
mmetric(test_target,pred_IBk_test,metrics_list) #test target eval
# k changed on IBk with train set perspectively
IBk_K_train <- IBk(train_target ~.,data = train_set,control= Weka_control(K = 5)) # ? lazy learner
# prediction models
pred_IBk_K_train <- predict(IBk_K_train,train_set) #train set predict
pred_IBk_K_test <- predict(IBk_K_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_IBk_K_train,metrics_list) #train target eval
mmetric(test_target,pred_IBk_K_test,metrics_list) #test target eval
# k changed on IBk with train set perspectively
IBk_I_train <- IBk(train_target ~.,data = train_set,control= Weka_control(I = TRUE)) # ?lazy learner
# prediction models
pred_IBk_I_train <- predict(IBk_I_train,train_set) #train set predict
pred_IBk_I_test <- predict(IBk_I_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_IBk_I_train,metrics_list) #train target eval
mmetric(test_target,pred_IBk_I_test,metrics_list) #test target eval
# k changed on IBk with train set perspectively
IBk_X_train <- IBk(train_target ~.,data = train_set,control= Weka_control(X = TRUE)) # ? lazy learner
# prediction models
pred_IBk_X_train <- predict(IBk_X_train,train_set) #train set predict
pred_IBk_X_test <- predict(IBk_X_train,test_set) #test set predict
# Evaluate performance "MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2"
mmetric(train_target,pred_IBk_X_train,metrics_list) #train target eval
mmetric(test_target,pred_IBk_X_test,metrics_list) #test target eval
# it's for 3 models
cv_function <- function(df, target, nFolds, seedVal, prediction_method, metrics_list)
{
# create folds using the assigned values
set.seed(seedVal)
folds = createFolds(df[,target],nFolds)
# The lapply loop
cv_results <- lapply(folds, function(x)
{
# data preparation:
test_target <- df[x,target]
test_input <- df[x,-target]
train_target <- df[-x,target]
train_input <- df[-x,-target]
pred_model <- prediction_method(train_target ~ .,data = train_input)
pred <- predict(pred_model, test_input)
return(mmetric(test_target,pred,metrics_list))
})
cv_results_m <- as.matrix(as.data.frame(cv_results))
cv_mean<- as.matrix(rowMeans(cv_results_m))
cv_sd <- as.matrix(rowSds(cv_results_m))
colnames(cv_mean) <- "Mean"
colnames(cv_sd) <- "Sd"
cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
kable(t(cv_all),digits=2)
}
df <- df_IBii_selected
target <- 8
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")
# For MLP
cv_function(df, target, 3, seedVal, MLP, metrics_list)
# For kSVM
cv_function(df, target, 3, seedVal, ksvm, metrics_list)
# For IBk
cv_function(df, target, 3, seedVal, IBk, metrics_list)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(RWeka)
library(kernlab)
library(rminer)
library(matrixStats)
library(knitr)
library(tictoc)
library(ggplot2)
library(dplyr)
library(rmarkdown)
library(tidyverse)
# Importing the dataset
na_sales <- read.csv("NA_sales_filtered.csv", stringsAsFactors = FALSE)
# Excluding the 'Name' column
na_sales <- na_sales[ , !(names(na_sales) %in% c('Name'))]
# Transforming character variables to factors
na_sales[sapply(na_sales, is.character)] <- lapply(na_sales[sapply(na_sales, is.character)], as.factor)
# Partitioning the dataset: 70% training and 30% testing
set.seed(123)
trainIndex <- createDataPartition(na_sales$NA_Sales, p = .7, list = FALSE, times = 1)
na_train <- na_sales[trainIndex,]
na_test <- na_sales[-trainIndex,]
summary(na_sales)
summary(na_sales)
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
# Building the MLP model with default settings
mlp_model_default <- MLP(NA_Sales ~ ., data = na_train)
metrics<-c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")
# Evaluating the model performance on the training set
mlp_train_pred_default <- predict(mlp_model_default, na_train)
mlp_test_pred_default <- predict(mlp_model_default, na_test)
train_eval<-mmetric(na_train$NA_Sales,mlp_train_pred_default,metrics)
test_eval<-mmetric(na_test$NA_Sales,mlp_test_pred_default,metrics)
train_eval
test_eval
# Calculating performance metrics
#mlp_train_perf_default <- postResample(mlp_train_pred_default, na_train$NA_Sales)
#mlp_test_perf_default <- postResample(mlp_test_pred_default, na_test$NA_Sales)
#list(mlp_test_pred_default = train_rmse, Train_MAE = train_mae,
#    mlp_test_pred_default = test_rmse, Test_MAE = test_mae)
# Building MLP model with two hidden layers and modified learning rate
mlp_model_tuned <- MLP(NA_Sales ~ ., data = na_train, control = Weka_control(H = 'a,a', L = 0.1))
# Evaluating the model performance on the training set
mlp_train_pred_tuned <- predict(mlp_model_tuned, na_train)
mlp_test_pred_tuned <- predict(mlp_model_tuned, na_test)
train_eval<-mmetric(na_train$NA_Sales,mlp_train_pred_tuned,metrics)
test_eval<-mmetric(na_test$NA_Sales,mlp_test_pred_tuned,metrics)
train_eval
test_eval
# Calculating performance metrics
#mlp_train_perf_tuned <- postResample(mlp_train_pred_tuned, na_train$NA_Sales)
#mlp_test_perf_tuned <- postResample(mlp_test_pred_tuned, na_test$NA_Sales)
#list(mlp_test_pred_default = train_rmse, Train_MAE = train_mae,
# mlp_test_pred_default = test_rmse, Test_MAE = test_mae)
# Building SVM model with default settings
svm_model_default <- ksvm(NA_Sales ~ ., data = na_train)
# Evaluating the model performance on the training set
svm_train_pred_default <- predict(svm_model_default, na_train)
svm_test_pred_default <- predict(svm_model_default, na_test)
train_eval<-mmetric(na_train$NA_Sales,svm_train_pred_default,metrics)
test_eval<-mmetric(na_test$NA_Sales,svm_test_pred_default,metrics)
train_eval
test_eval
# Calculating performance metrics
#svm_train_perf_default <- postResample(svm_train_pred_default, na_train$NA_Sales)
#svm_test_perf_default <- postResample(svm_test_pred_default, na_test$NA_Sales)
# Output the RMSE results
#list(svm_train_perf_default = svm_train_perf_default, svm_test_perf_default = svm_test_perf_default)
# Build SVM model with a different kernel function
svm_model_rbf <- ksvm(NA_Sales ~ ., data = na_train, kernel = 'rbfdot')
# Evaluate the model performance on the training set
svm_train_pred_rbf <- predict(svm_model_rbf, na_train)
svm_test_pred_rbf <- predict(svm_model_rbf, na_test)
train_eval<-mmetric(na_train$NA_Sales,svm_train_pred_rbf,metrics)
test_eval<-mmetric(na_test$NA_Sales,svm_test_pred_rbf,metrics)
train_eval
test_eval
# Calculate performance metrics
#svm_train_perf_rbf <- postResample(svm_train_pred_rbf, na_train$NA_Sales)
#svm_test_perf_rbf <- postResample(svm_test_pred_rbf, na_test$NA_Sales)
# Output theresults
#list(svm_train_perf_rbf = svm_train_perf_rbf, #svm_test_perf_rbf = svm_test_perf_rbf)
# Build SVM model with a different cost value
svm_model_cost <- ksvm(NA_Sales ~ ., data = na_train, C = 5)
# Evaluate the model performance on the training set
svm_train_pred_cost <- predict(svm_model_cost, na_train)
svm_test_pred_cost <- predict(svm_model_cost, na_test)
train_eval<-mmetric(na_train$NA_Sales,svm_train_pred_cost,metrics)
test_eval<-mmetric(na_test$NA_Sales,svm_test_pred_cost,metrics)
train_eval
test_eval
# Calculate performance metrics
#svm_train_perf_cost <- postResample(svm_train_pred_cost, na_train$NA_Sales)
#svm_test_perf_cost <- postResample(svm_test_pred_cost, na_test$NA_Sales)
# Output the RMSE results
#list(svm_train_perf_cost =svm_train_perf_cost, svm_test_perf_cost=svm_test_perf_cost)
# Build KNN model with default settings
knn_model_default <- IBk(NA_Sales ~ ., data = na_train)
# Evaluate the model performance on the training set
knn_train_pred_default <- predict(knn_model_default, na_train)
knn_test_pred_default <- predict(knn_model_default, na_test)
train_eval<-mmetric(na_train$NA_Sales,knn_train_pred_default,metrics)
test_eval<-mmetric(na_test$NA_Sales,knn_test_pred_default,metrics)
train_eval
test_eval
# Calculate performance metrics
#knn_train_perf_default <- postResample(knn_train_pred_default, na_train$NA_Sales)
#knn_test_perf_default <- postResample(knn_test_pred_default, na_test$NA_Sales)
#list(knn_train_perf_default = knn_train_perf_default, knn_test_perf_default = knn_test_perf_default)
# Build KNN model with K = 5
knn_model_k5 <- IBk(NA_Sales ~ ., data = na_train, control = Weka_control(K = 5))
# Evaluate the model performance on the training set
knn_train_pred_k5 <- predict(knn_model_k5, na_train)
knn_test_pred_k5 <- predict(knn_model_k5, na_test)
train_eval<-mmetric(na_train$NA_Sales,knn_train_pred_k5,metrics)
test_eval<-mmetric(na_test$NA_Sales,knn_test_pred_k5,metrics)
train_eval
test_eval
# Calculate performance metrics
#knn_train_perf_k5 <- postResample(knn_train_pred_k5, na_train$NA_Sales)
#knn_test_perf_k5 <- postResample(knn_test_pred_k5, na_test$NA_Sales)
#list(knn_train_perf_k5 = knn_train_perf_k5, knn_test_perf_k5 = knn_test_perf_k5)
# Build KNN model with weighted voting
knn_model_weighted <- IBk(NA_Sales ~ ., data = na_train, control = Weka_control(I = TRUE))
# Evaluate the model performance on the training set
knn_train_pred_weighted <- predict(knn_model_weighted, na_train)
knn_test_pred_weighted <- predict(knn_model_weighted, na_test)
train_eval<-mmetric(na_train$NA_Sales,knn_train_pred_weighted,metrics)
test_eval<-mmetric(na_test$NA_Sales,knn_test_pred_weighted,metrics)
train_eval
test_eval
# Calculate performance metrics
#knn_train_perf_weighted <- postResample(knn_train_pred_weighted, na_train$NA_Sales)
#knn_test_perf_weighted <- postResample(knn_test_pred_weighted, na_test$NA_Sales)
#list(knn_train_perf_weighted = knn_train_perf_weighted, knn_test_perf_weighted = knn_test_perf_weighted)
# Build KNN model with automatic K selection
knn_model_auto <- IBk(NA_Sales ~ ., data = na_train, control = Weka_control(X = TRUE))
# Evaluate the model performance on the training set
knn_train_pred_auto <- predict(knn_model_auto, na_train)
knn_test_pred_auto <- predict(knn_model_auto, na_test)
train_eval<-mmetric(na_train$NA_Sales,knn_train_pred_auto,metrics)
test_eval<-mmetric(na_test$NA_Sales,knn_test_pred_auto,metrics)
train_eval
test_eval
# Calculate performance metrics
#knn_train_perf_auto <- postResample(knn_train_pred_auto, na_train$NA_Sales)
#knn_test_perf_auto <- postResample(knn_test_pred_auto, na_test$NA_Sales)
#list(knn_train_perf_auto = knn_train_perf_auto, knn_test_perf_auto = knn_test_perf_auto)
cv_function <- function(df, target, nFolds, seedVal, metrics)
{
##a
set.seed(seedVal)
folds = createFolds(df[,target],nFolds)
cv_results <- lapply(folds, function(x)
{
train_target <- df[-x,-target]
train_input  <- df[x,-target]
test_target <- df[-x,target]
test_input <- df[x,target]
classification_model<- classification(data=train,formula=train_target~.)
pred_model<-method(train_target ~., data=train_input)
pred<- predict(classification_model,test_input)
pred<-predict(pred_model,test)
train_pred<-predict(pred_model,train_input)
##b
return(mmetric(test_target,pred,metrics))
})
##c
cv_results_m <- as.matrix(as.data.frame(cv_results))
cv_mean<- as.matrix(rowMeans(cv_results_m))
colnames(cv_mean) <- "Mean"
cv_sd <- as.matrix(rowSds(cv_results_m))
colnames(cv_sd) <- "Sd"
cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
##d
kable(cv_all,digits=2)
}
# Define the ksvm model function
# Define some example metrics
cv_function(na_sales, 8, 3, 500, MLP, metrics)
# it's for 3 models
cv_function <- function(df, target, nFolds, seedVal, prediction_method, metrics_list)
{
# create folds using the assigned values
set.seed(seedVal)
folds = createFolds(df[,target],nFolds)
# The lapply loop
cv_results <- lapply(folds, function(x)
{
# data preparation:
test_target <- df[x,target]
test_input <- df[x,-target]
train_target <- df[-x,target]
train_input <- df[-x,-target]
pred_model <- prediction_method(train_target ~ .,data = train_input)
pred <- predict(pred_model, test_input)
return(mmetric(test_target,pred,metrics_list))
})
cv_results_m <- as.matrix(as.data.frame(cv_results))
cv_mean<- as.matrix(rowMeans(cv_results_m))
cv_sd <- as.matrix(rowSds(cv_results_m))
colnames(cv_mean) <- "Mean"
colnames(cv_sd) <- "Sd"
cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
kable(t(cv_all),digits=2)
}
# Define the ksvm model function
# Define some example metrics
cv_function(na_sales, 8, 3, 500, MLP, metrics)
cv_function(na_sales, 8, 3, 500, ksvm,metrics)
cv_function(na_sales, 8, 3, 500, IBk, metrics)
#mlp_cv_results <- cv_function(na_sales, "NA_Sales", 3, 123, "mlp", metrics_list)
sort(itemFrequencyPlot(Dept_baskets,topN = 15,type='relative'), )
sort(itemFrequencyPlot(Dept_baskets,topN = 15,type='relative') )
sort(itemFrequencyPlot(Dept_baskets,topN = 15,type='relative'), decreasing = TRUE)
# Load the following packages. Install them first if necessary.
knitr::opts_chunk$set(echo = T, warning = F, Message=F)
options(rgl.useNULL = TRUE)
library(C50)
library(caret)
library(rpart)
library(rpart.plot)
library(rJava)
library(RWeka)
library(kernlab)
library(rminer)
library(matrixStats)
library(knitr)
library(tictoc)
library(tidyverse)
library(psych)
library(arules)
tic()
# Importing Data from input file
cloud_wd <- getwd()
setwd(cloud_wd)
cd <- read.csv(file = "Walmart_visits_7trips.csv", stringsAsFactors = F)
# Structure of Input File
str(cd)
# Mutating chr variales and target variable
cd_new <- cd %>%
mutate(DOW = factor(DOW),
TripType = factor(TripType))
# Summary of Input Data
summary(cd_new)
pairs.panels(cd_new)
# Building a C5.0 to keep leaves less than 15
tree_1 <- C5.0(TripType ~ .,data=cd_new,control = C5.0Control(CF = 0.2)) #tried .3 and .2 and .2 seems best.
tree_1
# Decision Tree Plot
plot(tree_1)
# Decision Model Summary
summary(tree_1)
# Confusion Matrix
preda <- predict(tree_1,cd_new)
mmetric(cd_new$TripType,preda,metric="CONF")$conf
# Building a C5.0 to keep leaves less than 15
tree_1 <- C5.0(TripType ~ .,data=cd_new,control = C5.0Control(CF = 0.2)) #tried .3 and .2 and .2 seems best.
tree_1
# Decision Tree Plot
plot(tree_1)
# Decision Model Summary
summary(tree_1)
# Confusion Matrix
preda <- predict(tree_1,cd_new)
mmetric(cd_new$TripType,preda,metric="CONF")$conf
# Storing target variables level count
TripType.levels <- unique(cd_new$TripType)
#Removing the Field
cd_rem <-  cd_new %>% select(-TripType)
Wkmeans <- SimpleKMeans(cd_rem, Weka_control(N=length(TripType.levels), init = 0, V=TRUE))
Wkmeans
Wkmeans2 <- SimpleKMeans(cd_rem, Weka_control(N=length(TripType.levels), init = 1, V=TRUE))
Wkmeans2
Wkmeans3 <- SimpleKMeans(cd_rem, Weka_control(N=length(TripType.levels), init = 1, V=TRUE, A= "weka.core.ManhattanDistance"))
Wkmeans3
Wkmeans4 <- SimpleKMeans(cd_rem, Weka_control(N=length(TripType.levels), init = 0, V=TRUE, A="weka.core.ManhattanDistance"))
Wkmeans4
# Reading Transactions
Dept_baskets <- read.transactions("Walmart_baskets_1week.csv", format="single", sep = ",", header = TRUE, cols=c("VisitNumber","DepartmentDescription"))
inspect(Dept_baskets[1:15])
sort(itemFrequencyPlot(Dept_baskets,topN = 15,type='relative'), decreasing = TRUE)
?lif
?lift
?apriori
library(tinytex)
library(tidyverse)
library(psych)
library(RWeka)
cloud_wd <- getwd()
setwd(cloud_wd)
titanic <- read.csv(file = "titanic.train.csv", stringsAsFactors = FALSE)
cloud_wd <- getwd()
setwd(cloud_wd)
titanic <- read.csv(file = "titanic.train.csv", stringsAsFactors = FALSE)
library(tinytex)
library(tidyverse)
library(psych)
library(RWeka)
library(tinytex)
library(tidyverse)
library(psych)
library(RWeka)
cloud_wd <- getwd()
setwd(cloud_wd)
titanic <- read.csv(file = "titanic.train.csv", stringsAsFactors = FALSE)
titanic %>% str()
tinytex::install_tinytex()
summary()
summary()?
end
library(tidyverse)
library(psych)
library(RWeka)
library(rmarkdown)
library(scatterplot3d)
library(caret)
# use getwd() and setwd() to set the working directory in rmarkdown file
mydir_wd <- getwd()
setwd(mydir_wd)
# Import a csv file
institution <- read.csv(file = "CD_additional_balanced.csv", stringsAsFactors = FALSE)
# use getwd() and setwd() to set the working directory in rmarkdown file
mydir_wd <- getwd()
setwd(mydir_wd)
# Import a csv file
institution <- read.csv(file = "CD_additional_balanced.csv", stringsAsFactors = FALSE)
institution$y <- factor(institution$y) # variable y factorization
institution$job <- factor(institution$job) # variable job factorization
institution$education <- factor(institution$education) # variable education factorization
institution$poutcome <- factor(institution$poutcome) # variable poutcome factorization
institution$marital <- factor(institution$marital) # variable marital factorization
institution$default <- factor(institution$default) # variable default factorization
institution$housing <- factor(institution$housing) # variable housing factorization
institution$loan <- factor(institution$loan) # variable loan factorization
institution$contact <- factor(institution$contact) # variable contact factorization
institution$month <- factor(institution$month) #variable month factorization
institution$day_of_week <- factor(institution$day_of_week) #variable day of week factorization
# show the overall "structure" of data
institution %>% str()
institution %>% summary() # SUMMARY FUNCTION HERE
# create local variables for row and column numbers
row <- nrow(titanic)
cloud_wd <- getwd()
setwd(cloud_wd)
titanic <- read.csv(file = "titanic.train.csv", stringsAsFactors = FALSE)
titanic %>% str()
titanic %>% select(Sex,Age) %>% head() # use head or tail to make sure we don't print the entire dataframe
?head()
?plot()
# correlations
institution %>% select(age, duration, campaign, pdays, euribor3m, emp.var.rate, nr.employed) %>% cor()
# Pair Panels
institution %>% select(age, duration, campaign, pdays, euribor3m, emp.var.rate, nr.employed) %>% pairs.panels()
install.packages('rpart')
install.packages('caret')
install.packages('rpart.plot')
install.packages('ISLR2')
install.packages("caret")
install.packages('rpart',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf.')
install.packages('caret',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf.')
install.packages('rpart.plot',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf.')
install.packages("caret", repos = "https://cran.r-project.org/web/packages/rpart/rpart.pdf.")
install.packages('ISLR2',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf.')
install.packages('rpart',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf')
install.packages('caret')
install.packages('rpart.plot',repos='https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf')
install.packages("caret")
install.packages('ISLR2')
install.packages('rpart',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf')
install.packages('caret',repos='https://cran.r-project.org/web/packages/caret/caret.pdf')
install.packages('rpart.plot',repos='https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf')
install.packages("caret", repos = "https://cran.r-project.org/web/packages/caret/caret.pdf")
install.packages('ISLR2')
install.packages('rpart',repos='https://cran.r-project.org/web/packages/rpart/rpart.pdf')
install.packages('caret',repos='https://cran.r-project.org/web/packages/caret/caret.pdf')
install.packages('rpart.plot',repos='https://cran.r-project.org/web/packages/rpart.plot/rpart.plot.pdf')
install.packages("caret", repos = "https://cran.r-project.org/web/packages/caret/caret.pdf")
install.packages('ISLR2',repos='https://cran.r-project.org/web/packages/ISLR2/ISLR2.pdf')
